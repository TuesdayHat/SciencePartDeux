examples of machine learning in action:
* Facebook facial recognition
* Kinects
* VR headset
* Speech to Text/voice recognition
* Robot dogs
* Ad delivery
* automatic recommendation
* space rovers
* map recognition/processing

Data Exhaust -- trail of data left by normal behavior. Logins, credit card usage, gps, etc.

Beginning of humanity => 2005, humans generate 130 Exabytes of data
  (Exabyte = 1000 Petabytes (1 Petabyte = 1000 Terabytes))
2005 - 2010 => 1200 Exabytes
2010 - 2015 => 7900 Eb
estimated 2015 - 2020 => 40,000 Eb

[installed Python and R -- 2:30 PM]
class is taught in both. I see no reason not to follow along in both.

Data Preprocessing
* Algorithm will fail unless data is in the right format

* Types of Variables:
  * Independent: use these to predict the dependent variable
  * Dependent: predicted variable

oh dear god indexes in R start at 1. Why.

python/Spyder IDE keyboard commands (Windows):
ctrl-enter => run in console
ctrl-i => inspect object
ctrl-1 => comment selected
